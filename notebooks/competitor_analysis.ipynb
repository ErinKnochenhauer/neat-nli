{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competitor Analysis\n",
    "\n",
    "The purpose of this notebook is to extract key competitor companies and products of a target company from proprietary interviews. The goal is to complete two tasks:\n",
    "1. Extract company and product names from expert interview transcripts\n",
    "2. Classify whether the company / product are competitors to the target company\n",
    "\n",
    "Desired output: \n",
    "* List of products and companies and whether they are a competitor to Snowflake ranked in order of importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erinknochenhauer/.local/share/virtualenvs/tegus-aQ_93WNH/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-08-22 21:03:07.113193: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    BartForSequenceClassification,\n",
    "    BartTokenizer\n",
    ")\n",
    "from transformers import pipeline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'utterances': [{'paragraphs': ['So currently researching the data analytics '\n",
      "                                \"space. So I have a bunch of questions I'd \"\n",
      "                                'love to go through. And I have a bit of your '\n",
      "                                'background, but it would be helpful if we '\n",
      "                                'could just spend a second with you telling '\n",
      "                                'you about your background. And also, I guess, '\n",
      "                                \"yes, I don't know if there's something you \"\n",
      "                                'are doing currently or just if we want to '\n",
      "                                'talk about Verve for this conversation? And '\n",
      "                                'if so, like what Verve does?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['Sure. Well so if you have my resume, Verve '\n",
      "                                'had an exit in January, where the company '\n",
      "                                'assets, including the name were sold to '\n",
      "                                'another company. So I can speak about what I '\n",
      "                                \"did a Verve for about 6 years, if that's \"\n",
      "                                \"something that you'd like to. But Verve as a \"\n",
      "                                'company is not quite what it was and as '\n",
      "                                'pertaining to my experience. So just be aware '\n",
      "                                \"of that. And as far as what I've done, I've \"\n",
      "                                \"got over 2 decades of tech experience, I've \"\n",
      "                                'built front ends systems and back end '\n",
      "                                'systems.',\n",
      "                                \"Every job I've had. I started as an \"\n",
      "                                'individual contributor engineer, I was '\n",
      "                                'promoted to tech leads and then to director '\n",
      "                                'levels and then DP level management. And '\n",
      "                                'Verve is a shining example of the journeys '\n",
      "                                \"that I've gone on in startup companies. I \"\n",
      "                                'self was hired as the solo engineer. I built '\n",
      "                                'a team around the ad tech technology that I '\n",
      "                                'built first hand.',\n",
      "                                'And then I was promoted to manage several '\n",
      "                                'teams where I manage QA, operations, data and '\n",
      "                                \"front-end development. And so I've not only \"\n",
      "                                \"done almost all of those roles, I've managed \"\n",
      "                                \"all those roles as well. And I've been \"\n",
      "                                'involved in due diligence and acquisitions '\n",
      "                                \"and I've also been a chief architect with \"\n",
      "                                'regards to technology selections and '\n",
      "                                \"migrations. So that's my background.\"],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Okay. And then I guess, what are the '\n",
      "                                \"platforms that you've used for data analytics \"\n",
      "                                'or data science?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': [\"Yes. So there's been a combination of home \"\n",
      "                                'rolled. So keep in mind, my experience '\n",
      "                                'predates current cloud offerings. And so more '\n",
      "                                'recent experience has been in those cloud '\n",
      "                                'offerings. When it comes to doing machine '\n",
      "                                'learning. And so my machine learning '\n",
      "                                'experience is in the ad tech space. And so I '\n",
      "                                'can speak very confidently about the ad tech '\n",
      "                                'space. Other domains may have subtle '\n",
      "                                \"variations to what I'm about to say. But in \"\n",
      "                                'general, you have the data producer. And in '\n",
      "                                'the case of ad tech, we have an ad server.',\n",
      "                                'Someone goes to a website, they want to see '\n",
      "                                'an ad. They go to a mobile app, they want to '\n",
      "                                'see an ad. I built the technology that would '\n",
      "                                'deliver the ad tag itself that would show the '\n",
      "                                'ad, right? That add would generate tons of '\n",
      "                                'data. And in the case of the system that I '\n",
      "                                'managed 12.0 to 20.0 terabytes was the range '\n",
      "                                'that we managed over time. And now all of '\n",
      "                                \"that data would get sense. So my team's \"\n",
      "                                'responsibility at first was to take that '\n",
      "                                \"data, you put it to what's known as a data \"\n",
      "                                'pipeline.',\n",
      "                                'And then that pipeline will put it into a '\n",
      "                                'data repository, and people use the terms '\n",
      "                                'data lakes and databases and all that stuff. '\n",
      "                                \"I'm just going there's a place where all the \"\n",
      "                                \"data lives, and there's a variety of ways of \"\n",
      "                                'storing the data. That in general, in ad '\n",
      "                                \"tech, that's the way the division of labor. \"\n",
      "                                'So the ad tech would get into that. And then '\n",
      "                                \"and I've managed teams and work with the \"\n",
      "                                'teams and you do processes to take the data '\n",
      "                                'out of that data repository and then turn it '\n",
      "                                'into something useful.',\n",
      "                                'And long ago, when I was at Rubicon the way '\n",
      "                                'that we did that is that we would stuff all '\n",
      "                                'that data into just a giant MySQL database, '\n",
      "                                'and then we would run queries that would '\n",
      "                                'aggregate the data in to smaller and smaller '\n",
      "                                'sets, and then that would be used to '\n",
      "                                \"represent reporting. Now that's over 10 years \"\n",
      "                                'ago. I mean that was the old days. These '\n",
      "                                \"days, there's numerous companies that they \"\n",
      "                                'call them BI tools in general.',\n",
      "                                'Not all BI tools are equal, but a lot of '\n",
      "                                'these business intelligence tools are able to '\n",
      "                                'read into your database and then provide the '\n",
      "                                \"front end visualizations. And I mean, I don't \"\n",
      "                                'even know, you probably could name more than '\n",
      "                                \"I could. I've worked with a couple. As a \"\n",
      "                                'matter of fact, one of the names is escaping '\n",
      "                                \"me right now. It'll come to me. And so you \"\n",
      "                                'have those visualizations.',\n",
      "                                'Now in between, and this is all background '\n",
      "                                \"because now I think what you're calling me \"\n",
      "                                'about is all the technology that manages that '\n",
      "                                'data repository and the reformatting in order '\n",
      "                                \"to service the BI tools, right? And I'm using \"\n",
      "                                'business intelligence very broadly, right? '\n",
      "                                \"It's just something that you would use to \"\n",
      "                                'explore a data set, right? Are we on the same '\n",
      "                                'page so far?'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': [\"Yes. I think so, I don't have a \"\n",
      "                                'supertechnical background so, but I am '\n",
      "                                'curious. So I think maybe if you can talk '\n",
      "                                'about this in between the visualizations and '\n",
      "                                'I guess, maybe where the data is stored. I '\n",
      "                                \"think maybe it's the in between layer.\"],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['Okay. Great. And I was trying to give the '\n",
      "                                'background to make sure that if I start using '\n",
      "                                \"terms that you're not familiar with, you at \"\n",
      "                                'least you\\'d now to ask, \"Hey, can you say '\n",
      "                                'that again\". So I\\'ll do my best. So now once '\n",
      "                                'all the day that gets into this data '\n",
      "                                \"repository, there's a variety of tools that \"\n",
      "                                \"people use and there's techniques and tools. \"\n",
      "                                'And specifically, when I was reached out '\n",
      "                                'about this call, they were asking about '\n",
      "                                'Databricks.',\n",
      "                                'And I think Snowflake may have come up, and '\n",
      "                                'they were also talking about Elastic '\n",
      "                                \"MapReduce. And so there's a variety of \"\n",
      "                                'technologies. What happened between 10, 12 '\n",
      "                                'years ago and last 3, 4, 5 years is that the '\n",
      "                                'technical problems of wrangling the data and '\n",
      "                                'feeding it into a machine learning system and '\n",
      "                                'whether you built it yourself or you as a '\n",
      "                                'cloud provider, machine learning system. '\n",
      "                                \"Those things became, well so they're \"\n",
      "                                \"technically challenging, but it's also once \"\n",
      "                                \"you've solved that problem, it's kind of the \"\n",
      "                                'same problem, right?',\n",
      "                                \"So there's an open source project called \"\n",
      "                                'Spark, which Databricks is built on. People '\n",
      "                                \"have used Spark. There's other pipeline \"\n",
      "                                \"systems. I mean, I don't even know how many \"\n",
      "                                'different pipeline systems, but the original '\n",
      "                                'was MapReduce, which came out of Google and '\n",
      "                                \"probably late 2000s, '08, '06, '08 somewhere \"\n",
      "                                'around that, pardon me for forgetting the '\n",
      "                                'exact history. But around then is kind of '\n",
      "                                'system started getting popular, right? So '\n",
      "                                \"there's companies that do this. And that is, \"\n",
      "                                \"I think what we're scheduled to talk about. \"\n",
      "                                'Does that sound about right?'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Yes. Yes. So I guess, have you been a '\n",
      "                                'customer of Databricks or Snowflakes or any '\n",
      "                                'of the cloud provider versions of those '\n",
      "                                'things?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['Yes. So I mean at Verve, we used Snowflake '\n",
      "                                'and EMR extensively. I personally have built '\n",
      "                                \"systems on Redshift, I've built MapReduce \"\n",
      "                                \"personally as an engineer, I've done that \"\n",
      "                                'myself. I managed the team at Verve that had, '\n",
      "                                \"well so I mean we did a lot of things. I've \"\n",
      "                                'worked on a team with data scientists. So I '\n",
      "                                'might call myself an honorary data scientist, '\n",
      "                                \"but I worked with PhD level people who'd \"\n",
      "                                'studied and had pedigrees and were intimately '\n",
      "                                'familiar with data science.',\n",
      "                                'I worked on those teams to build the '\n",
      "                                'technology that would do to the machine '\n",
      "                                'learning. And so at Verve, the way that we '\n",
      "                                'did machine learning, Verve predated a lot of '\n",
      "                                'the cloud offerings. So for example, and both '\n",
      "                                'Amazon and Google, probably Azure as well, '\n",
      "                                'offer a way for you, you can pump data into '\n",
      "                                \"their system and then they'll manage like a \"\n",
      "                                'managed machine learning system that will do '\n",
      "                                'a lot of the stuff for you and make it '\n",
      "                                'easier.',\n",
      "                                \"At Verve, we couldn't use those because \"\n",
      "                                'basically, they were too expensive. In ad '\n",
      "                                \"tech, you're dealing with, a lot of people \"\n",
      "                                \"will say big data, and they'll be talking \"\n",
      "                                'about a 1 gig or 2 gig of data. I mean we '\n",
      "                                'literally dealt with terabytes a day. And at '\n",
      "                                'that volume, those managed systems tend to '\n",
      "                                'get very expensive. We did work with '\n",
      "                                'Snowflake.',\n",
      "                                'So when I described to you earlier, the '\n",
      "                                'pipeline of how the data would get from the '\n",
      "                                'ad server into the data repository at Verve, '\n",
      "                                'we used a few different technologies along '\n",
      "                                'the way, but ended up landing at Snowflake. '\n",
      "                                'And so Snowflake was a very good offering for '\n",
      "                                'storing data. And also, the original e-mail '\n",
      "                                \"that was sent me asked me if I'd ever \"\n",
      "                                'evaluated Databricks. And in 2016, I indeed, '\n",
      "                                'did an extremely deep dive.',\n",
      "                                'We did a prototype with Databricks. At that '\n",
      "                                \"time, I don't know if you familiar with \"\n",
      "                                \"Databricks' history, but that was a time they \"\n",
      "                                'were starting to get -- they started getting '\n",
      "                                'serious funding around this time. So I '\n",
      "                                'probably evaluated them just before they were '\n",
      "                                'starting to supercharge their offering. And '\n",
      "                                \"so at the time, it wasn't suitable for us. So \"\n",
      "                                'we chose to build instead of buy at that '\n",
      "                                'time.',\n",
      "                                \"And we built on Elastic's MapReduce inside of \"\n",
      "                                'Amazon because at that time, the flexibility '\n",
      "                                \"that we required just wasn't available with \"\n",
      "                                'Databricks. That being said, Databricks was a '\n",
      "                                'very nice product. We were mixed. I mean, '\n",
      "                                \"there it was called or so some of us didn't \"\n",
      "                                'so.'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Okay. So I guess, if you could just explain '\n",
      "                                'briefly like what each of Snowflake, '\n",
      "                                'Databricks and EMR like does and their value '\n",
      "                                'proposition?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': [\"Okay. So I'll start with EMR because it's the \"\n",
      "                                'oldest one. It stands for Elastic MapReduce. '\n",
      "                                'MapReduce is a computing technique where you '\n",
      "                                'take data and you chunk it up into little '\n",
      "                                'chunks. You send it out to lots of computers '\n",
      "                                \"to process it. And that's the mapping part. \"\n",
      "                                'So mapping is putting it out to tens or '\n",
      "                                'hundreds of computers to and each computer '\n",
      "                                'would do its own little processing of that '\n",
      "                                'chunk and then reduces to take all that and '\n",
      "                                'then put it all back together in aggregate '\n",
      "                                'it.',\n",
      "                                \"So that's the MapReduce technique. Elastic \"\n",
      "                                \"MapReduce. So in 2008, '10 era, if you were \"\n",
      "                                'doing Elastic MapReduce, back then, you would '\n",
      "                                'have to either buy a bunch of computers and a '\n",
      "                                'data center or you would have to pay for a '\n",
      "                                'ton of cloud instances inside of Amazon. And '\n",
      "                                'the thing about EMR jobs, that mapping and '\n",
      "                                'reducing that EMR job. A lot of times, those '\n",
      "                                'jobs would be temporary.',\n",
      "                                'So for example, one use case in ad tech is '\n",
      "                                'daily reporting. So I would generate 12 '\n",
      "                                'terabytes of data in a day. And then I need '\n",
      "                                'to process it. And I would run my process job '\n",
      "                                \"and let's say my job takes 6 hours, right? \"\n",
      "                                'Well, in the old days, I would have to pay '\n",
      "                                'for 24 hours of compute capability to handle '\n",
      "                                'that really high load at those 6 hours, '\n",
      "                                'right? It was very inconvenient to shut it '\n",
      "                                'off and turn it back on.',\n",
      "                                'So Amazon created a product called EMR, '\n",
      "                                'Elastic MapReduce, and the elasticity is that '\n",
      "                                'you send a job to entitle the system, you '\n",
      "                                'send the job and then will automatically and '\n",
      "                                \"it's a configurable way, but it will \"\n",
      "                                'automatically spin up all the temporary cloud '\n",
      "                                'computers that you need to run your job and '\n",
      "                                'then shut them off when your job is over '\n",
      "                                'automatically. And so that became a very '\n",
      "                                'convenient way to do data processing. Does '\n",
      "                                'that make sense?'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Yes.'], 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['Great. So Snowflake is not the same '\n",
      "                                \"technology. Snowflake is, I'm not sure if \"\n",
      "                                'they would call themselves a data lake, '\n",
      "                                \"they'd probably be part of the data lakes. I \"\n",
      "                                \"honestly don't understand the term data lake \"\n",
      "                                \"just because it's used in so many different \"\n",
      "                                \"ways. To me, Snowflake is, I'm going to call \"\n",
      "                                \"it a database, even though they're much more \"\n",
      "                                'than that.',\n",
      "                                'What Snowflake does is most databases before '\n",
      "                                'Snowflake, you would be able to, if you had a '\n",
      "                                'lot of data, you could either add more '\n",
      "                                'servers or you could make bigger servers, '\n",
      "                                'right? And it was very, and most database '\n",
      "                                \"systems don't allow you to add more or bigger \"\n",
      "                                'servers easily, right? As an example, '\n",
      "                                'Redshift is a similar technology to '\n",
      "                                'Snowflake, in that it stores data. Redshift, '\n",
      "                                'when you wanted to add instances to it, '\n",
      "                                'Redshift is a cloud offering from Amazon, '\n",
      "                                \"it's old.\",\n",
      "                                \"I mean, I used it in 2012, '13. One of the \"\n",
      "                                'pain points with Redshift is that even though '\n",
      "                                \"it's running in the cloud, it wasn't elastic, \"\n",
      "                                'the same way I described Elastic MapReduce. '\n",
      "                                \"It wasn't elastic. You would have to hit a \"\n",
      "                                'button in the UI, and then it could take, '\n",
      "                                'depending on the size of your data set, 24, '\n",
      "                                '48, 72 hours for your server upgrade to '\n",
      "                                \"happen. And if you're interested, I can tell \"\n",
      "                                'you the technical reasons why that is, but '\n",
      "                                \"that's just the way that it was.\",\n",
      "                                'Snowflake in contrast is Elastic in the same '\n",
      "                                'way the EMR is, so Snowflake allows you to '\n",
      "                                'add more. So if you have a big job, when '\n",
      "                                \"you're running these EMR jobs, you have to \"\n",
      "                                \"pull the data from somewhere. If you're \"\n",
      "                                'pulling the data from a database that is one '\n",
      "                                'size, it only has a certain amount of '\n",
      "                                'throughput, maybe it can push 100 megabit per '\n",
      "                                \"second. But if that's all it can push, that's \"\n",
      "                                'it.',\n",
      "                                \"And if you're stuck with 100 megabit, you \"\n",
      "                                'have to wait, even though you might have a '\n",
      "                                'fleet of servers that can process 200 megabit '\n",
      "                                'per second, if your database can only output '\n",
      "                                \"100 megabit per second, you're stuck with \"\n",
      "                                \"that database. And that's what Snowflake's \"\n",
      "                                \"superpower is. Snowflake, you're like, oh, I \"\n",
      "                                \"got a really big job. I don't want 100 -- I \"\n",
      "                                'want 500 megabit per second of data to flow '\n",
      "                                'out of this thing, and you can do that with '\n",
      "                                'Snowflake, and they bring it up very quickly.',\n",
      "                                'Like it is almost magical, how they do it. I '\n",
      "                                \"honestly don't understand how their \"\n",
      "                                'technology works enough. But I will tell you '\n",
      "                                'that as a technologist, I find it magical, '\n",
      "                                \"and it's a pretty incredible product. Does \"\n",
      "                                'that make sense?'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Yes.'], 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': [\"So EMR is a way of processing data that it's \"\n",
      "                                'a technique for spreading out the data to '\n",
      "                                \"different servers to process it. That's \"\n",
      "                                \"different than Snowflake. I don't know, at \"\n",
      "                                'Snowflake may, well so forgive me for not '\n",
      "                                'knowing every aspect of their capabilities, '\n",
      "                                \"but I don't know if they have built in \"\n",
      "                                'processing. My understanding is that they '\n",
      "                                \"don't. But it's basically Snowflake is an \"\n",
      "                                'elastic database, right?',\n",
      "                                \"And there's other elastic database solutions. \"\n",
      "                                'Back in the day, that NoSQL solutions were '\n",
      "                                'offered in comparison to NoSQL solutions, a '\n",
      "                                \"lot of NoSQL solutions, they didn't have \"\n",
      "                                \"atomic data management. And so I don't know \"\n",
      "                                \"if you're interested in understanding that \"\n",
      "                                \"distinction, I could explain it if you'd \"\n",
      "                                'like.'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['I think that will probably be a little too '\n",
      "                                'technical.'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['Okay. All right. So just in review, EMR, a '\n",
      "                                'way of processing lots of data, Snowflake, a '\n",
      "                                'scalable way of storing lots of data. Now '\n",
      "                                'when we talk about Databricks, some people '\n",
      "                                'will disparage may call a Databricks a '\n",
      "                                'glorified front end, a glorified UI on top of '\n",
      "                                'Apache Spark. So what Apache Spark is a '\n",
      "                                'system for doing machine learning.',\n",
      "                                'Now machine learning basically is you take a '\n",
      "                                'bunch of data, you give it to a computer '\n",
      "                                'program that implements a machine learning '\n",
      "                                \"algorithm. There's lots of different \"\n",
      "                                'algorithms. And when you feed at that data, '\n",
      "                                'it learns using different machine learning '\n",
      "                                'algorithms, it will start to be able to '\n",
      "                                'recognize patterns.',\n",
      "                                \"So that's called training. When you train a \"\n",
      "                                'machine learning algorithm, what comes out of '\n",
      "                                'it is a model. And then that model can be '\n",
      "                                \"used to recognize things that it's never seen \"\n",
      "                                'before as belonging to some classification, '\n",
      "                                'right?',\n",
      "                                \"So what you're doing is you're classifying \"\n",
      "                                'your data. So you have a bunch of data in '\n",
      "                                'Snowflake, you could use EMR to pull the data '\n",
      "                                'out and then do some processing. And when you '\n",
      "                                'can break it up in a little tiny chunks and '\n",
      "                                'you feed it to one of these machine learning '\n",
      "                                'things, right? Now in olden times, 5, 10 '\n",
      "                                'years ago, when to do that, a lot of '\n",
      "                                'engineers would literally have to write '\n",
      "                                'scripts themselves.',\n",
      "                                'And a common language for that is Python. And '\n",
      "                                \"so there's a lot of nice programming \"\n",
      "                                'libraries in Python to do that kind of stuff. '\n",
      "                                'What Databricks does is it provides a nice '\n",
      "                                'user interface, a web user interface that '\n",
      "                                'allows you to stitch those scripts together, '\n",
      "                                'write some custom scripts, if you had to, but '\n",
      "                                'it allows you to give you like some WYSIWYG '\n",
      "                                'point and click niceties in order to manage '\n",
      "                                'these jobs, right, because where a lot of '\n",
      "                                \"people don't recognize how technical.\",\n",
      "                                \"It seems so easy, it's like, oh, there's a \"\n",
      "                                'cloud service, stuff your data in and then '\n",
      "                                \"you get it out. That's easy to say. The \"\n",
      "                                'mechanics of getting huge amounts of data '\n",
      "                                'from one server to a different server over '\n",
      "                                'the network securely, reliably and '\n",
      "                                \"consistently. It's surprisingly difficult. \"\n",
      "                                'And so when people are writing scripts, as '\n",
      "                                'engineers are writing scripts all the time, '\n",
      "                                \"every time they write a new script, there's \"\n",
      "                                'some little nuance detail that they might be '\n",
      "                                'missing.',\n",
      "                                \"That's where these software libraries come \"\n",
      "                                \"from that you make enough mistakes, you're \"\n",
      "                                'like, oh, I need to write this thing, so it '\n",
      "                                'does it right every time. And so stitching '\n",
      "                                'all those little parts together to get the '\n",
      "                                'data from one server to the other back and '\n",
      "                                'aggregating and all those things correctly, '\n",
      "                                'could be complicated if you have to do it my '\n",
      "                                'hand every time. So Databricks, in summary, '\n",
      "                                'provides a nice way of making that reliable '\n",
      "                                'and more consistent and easier to manage.'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': [\"Okay. That's helpful. So I guess what would \"\n",
      "                                'be helpful is if you could walk me through '\n",
      "                                'the competitive landscape, I guess, like '\n",
      "                                'whether you see, what, I guess, the direct '\n",
      "                                'competitors are for Snowflake and Databricks. '\n",
      "                                'And whether you consider them direct '\n",
      "                                'competitors. Just trying to get a light of '\n",
      "                                'like what the different offerings are and '\n",
      "                                'sort of where they lie on the spectrum?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': [\"Well, I can tell you, I mean, I can't offer \"\n",
      "                                'you a complete competitive landscape. I can '\n",
      "                                'tell you the things that I have experienced '\n",
      "                                'with, if that would be helpful.'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Yes. And I guess, if you can tell me like '\n",
      "                                'what you chose to evaluate. And also if there '\n",
      "                                'were though offerings that you knew were out '\n",
      "                                'there but chose not to evaluate if let me '\n",
      "                                'know why that would be helpful as well.'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['Yes. So in order to have this conversation '\n",
      "                                \"completely, I do need to mention that there's \"\n",
      "                                'another class of technology. So these 3 '\n",
      "                                'things that you ask me about, I consider '\n",
      "                                'those, and I think most people would agree '\n",
      "                                'with me, those are 3 different types of '\n",
      "                                'technology. One is a machine learning, '\n",
      "                                'Databricks is a machine learning pipeline '\n",
      "                                'management system. Snowflake is a database, a '\n",
      "                                'very fancy database, but a database '\n",
      "                                'nonetheless. And then EMR is a pipeline '\n",
      "                                'system, right?',\n",
      "                                \"So there's a or so that EMR is the pipeline \"\n",
      "                                'and Databricks is the management of the '\n",
      "                                'pipeline, right? So those 3, actually, you '\n",
      "                                'can use all 3 of those together. I believe '\n",
      "                                'that, like that is probably a common stack in '\n",
      "                                \"Databricks. Like if you're a Databricks \"\n",
      "                                \"customer, I'm almost certain that, you'll be \"\n",
      "                                'using those technologies. And then those EMR '\n",
      "                                'jobs will be pushing the data into what is '\n",
      "                                'Spark, which is the underlying technology for '\n",
      "                                'Databricks.',\n",
      "                                \"So now there's another class of database \"\n",
      "                                'called NoSQL databases that I mentioned '\n",
      "                                \"earlier. We don't need to get into the \"\n",
      "                                \"details. Just need to know that there's \"\n",
      "                                'another class and databases. Some of those '\n",
      "                                'are Cassandra, MongoDB, Couchbase. I think '\n",
      "                                \"Amazon's offerings is called Dynamo. Google \"\n",
      "                                'has one as well. You do need to know just for '\n",
      "                                'purposes discussion, that there is an entire '\n",
      "                                'class of databases that are commonly used '\n",
      "                                'with EMR that are not like Snowflake.',\n",
      "                                \"Snowflake is special because it's a SQL \"\n",
      "                                'database, SQL, as a structure query language. '\n",
      "                                'Snowflake allows you to store relational '\n",
      "                                'data. And then these NoSQL databases, their '\n",
      "                                'strength is storing large amounts of data and '\n",
      "                                'not necessarily managing the relationships '\n",
      "                                'between the data, right? Does that make sense '\n",
      "                                'between NoSQL and Snowflake?'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Yes.'], 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['All right. Now when it comes to what is in '\n",
      "                                'the market, so based on the questions that '\n",
      "                                'you asked me so far, that your interest in '\n",
      "                                'how this pertains to machine learning. Is '\n",
      "                                'that the primary use case you want me to '\n",
      "                                'speak within?'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Yes. I think so, like focusing on the '\n",
      "                                \"competitors of Databricks, and I think that's \"\n",
      "                                'the most helpful. But it was helpful for me '\n",
      "                                'to understand like what you can use in '\n",
      "                                'combination to because my understanding so '\n",
      "                                \"far is like there's Databricks, there's \"\n",
      "                                'Snowflake and then it seems like Azure has '\n",
      "                                'sort of 5 different tools and Amazon has 5 '\n",
      "                                'different tools. And Google, I guess, has big '\n",
      "                                \"and I'm trying to understand what's \"\n",
      "                                'comparable to what?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['Yes. So one thing you might not be aware some '\n",
      "                                \"of the technologies that you're mentioning \"\n",
      "                                'are actually technically different '\n",
      "                                'technologies, right? Like you asked me a '\n",
      "                                'question about EMR, Snowflake and Databricks. '\n",
      "                                'Those are 3 different technologies that you '\n",
      "                                'can actually use altogether. And for every '\n",
      "                                \"one of those, one of them is Amazon's cloud \"\n",
      "                                \"offering, but you're correct.\",\n",
      "                                'In all the Azure, Google Cloud and AWS, all 3 '\n",
      "                                'of them have multiple versions of all these. '\n",
      "                                'I mean, I think Google has like 6 different '\n",
      "                                'databases, right? So it can get confusing in '\n",
      "                                'a hurry. I think Forrester or Gartner, I '\n",
      "                                \"don't know if you have a subscription to \"\n",
      "                                'them, but one of those guaranteed has a '\n",
      "                                \"beautiful paper. I've seen both of the work \"\n",
      "                                'that they put out.',\n",
      "                                'And breaking down the industry, you might '\n",
      "                                'consider looking at one of those because they '\n",
      "                                'break down what the different technologies '\n",
      "                                'mean and I suppose it was Gartner that has a '\n",
      "                                'magic quadrant, right? So a lot of times, '\n",
      "                                'there are magic quadrants so, and those '\n",
      "                                \"papers, they'll break down what the different \"\n",
      "                                'technology definitions are. So as far as or '\n",
      "                                'so if we want to talk about competitors to '\n",
      "                                'Databricks, trying to think.',\n",
      "                                \"So Google has a data flow. Amazon's EMR, \"\n",
      "                                \"inside of Amazon, though, they've got another \"\n",
      "                                'tool that would help you with -- specifically '\n",
      "                                \"with machine learning. I don't remember the \"\n",
      "                                'name of it. But all of these technologies '\n",
      "                                'layer on top of each other. And so as far as '\n",
      "                                'like who Databricks would consider to be a '\n",
      "                                'competitor? I have to think about that. '\n",
      "                                \"There's something called data stacks. And \"\n",
      "                                'these are 4 year old memories in them. Do you '\n",
      "                                'mind if I do a little research online?'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': [\"Oh, sure. I guess that they don't come top of \"\n",
      "                                \"mind like that's good to know. I guess then, \"\n",
      "                                'how about for Snowflake, I guess. So '\n",
      "                                'understanding that Snowflake is a SQL '\n",
      "                                \"database and they're NoSQL databases, or I \"\n",
      "                                'guess you have to know a language other than '\n",
      "                                'SQL to use them. I guess what would be the '\n",
      "                                'competitors to Snowflake?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['So competitors to Snowflake, quite honestly, '\n",
      "                                'if I was investing in Snowflake, this is my '\n",
      "                                'personal opinion, like, one of the things '\n",
      "                                'knowing what I know about just general about '\n",
      "                                'technology. Is that Amazon and Google and '\n",
      "                                \"probably Azure. I'm just less familiar with \"\n",
      "                                'Azure, but I assume that they would be doing '\n",
      "                                'the same thing. All 3 of them have a similar '\n",
      "                                'technology, right? Database technologies have '\n",
      "                                'been -- Oracle is probably building something '\n",
      "                                'like this, right?',\n",
      "                                'So Snowflake is up against, they run on these '\n",
      "                                'cloud platforms that are themselves building '\n",
      "                                'it, right? So that becomes a major '\n",
      "                                'competitive risk. Now based on my following '\n",
      "                                \"the Snowflake, it hasn't negatively impacted \"\n",
      "                                'their stock price or valuation, right? And so '\n",
      "                                'they seem to be managing that well. If you '\n",
      "                                'had asked me 5 years ago, I would have said '\n",
      "                                'Snowflake has no chance, I was wrong. A major '\n",
      "                                'competitor to Snowflake.',\n",
      "                                'Now that snowpack has had success, there was '\n",
      "                                'certainly going to be other technologies that '\n",
      "                                \"will rise and we'll get funding, right? So \"\n",
      "                                \"I'm not sure exactly which ones, but I mean \"\n",
      "                                \"there's hundreds of open source scalable \"\n",
      "                                'databases. NoSQL is one particular class of '\n",
      "                                'them.',\n",
      "                                'And then as far as SQL solutions, the Apache '\n",
      "                                'foundation has several as well. One pattern '\n",
      "                                \"that's happened in the industry is that \"\n",
      "                                'Google has a history of using a technology '\n",
      "                                'for a while, building a new version and then '\n",
      "                                'open sourcing the old one. And then the open '\n",
      "                                'source one becomes popular. Meanwhile, Google '\n",
      "                                'has moved on to the new one. This happened '\n",
      "                                'with a database of there is called Spanner. '\n",
      "                                \"So there's an open source version of Spanner \"\n",
      "                                'and Spanner is one of the offerings that they '\n",
      "                                'have inside of Google Cloud.'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': [\"Okay. I don't understand what--\"],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['I do have one other thought. With Snowflake, '\n",
      "                                'one of the things, though, about all those '\n",
      "                                \"systems that are in the cloud, they're \"\n",
      "                                \"expensive, right? And so there's kind of 3 \"\n",
      "                                'levels of expense, in my opinion. One is do '\n",
      "                                'it yourself, run the cloud instances '\n",
      "                                'yourself. Level 2 would be Snowflake, which '\n",
      "                                'is they charge a tiny, relatively small fee, '\n",
      "                                \"you're paying for your instances and then a \"\n",
      "                                'little bit more for Snowflake.',\n",
      "                                \"And then there's the managed solutions inside \"\n",
      "                                'of the cloud systems themselves. And the '\n",
      "                                'advantage with Snowflake over those systems '\n",
      "                                'is that you will pay less with Snowflake than '\n",
      "                                'you would using the equivalent technology '\n",
      "                                'inside of Google on Google system, right, '\n",
      "                                'same thing with Amazon. So that pricing '\n",
      "                                'strata allows companies to make choices, '\n",
      "                                'trade-off choices as far as cost versus '\n",
      "                                'engineering resources to build it yourself.',\n",
      "                                \"And what I've noticed is that a lot of times, \"\n",
      "                                'companies start with the expensive stuff '\n",
      "                                \"because when you're 5 people or a small \"\n",
      "                                \"company, it's not that expensive. But then as \"\n",
      "                                \"you grow, you're like Holy cow. So conversely \"\n",
      "                                'to the competitive pressure that Snowflake '\n",
      "                                'would feel if they can keep their pricing '\n",
      "                                'competitive, then they actually have an '\n",
      "                                \"advantage, right? So that's just another \"\n",
      "                                \"viewpoint that I'd like to share.\"],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Okay. That makes sense. I guess, so aside '\n",
      "                                'cost though, what would you say are the '\n",
      "                                'things that make Snowflake unique or that are '\n",
      "                                'there key advantages?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['Yes. So the major advantage with Snowflake is '\n",
      "                                'that the dynamic allocation. They also have a '\n",
      "                                'very slick user interface as well. I '\n",
      "                                'personally have used it to do data splunking. '\n",
      "                                \"And so they've got really nice UI, they make \"\n",
      "                                \"it very convenient. It's a SQL like language. \"\n",
      "                                \"There's a standard called the ANSI standard \"\n",
      "                                'for SQL, and they implement a lot of that '\n",
      "                                'plus some extra. The ability to dynamically '\n",
      "                                'adjust your workloads. They also have a lot '\n",
      "                                'in an enterprise situation.',\n",
      "                                'You have a lot of data is valuable, and you '\n",
      "                                'need to keep it secure and isolated and '\n",
      "                                'protected from different groups. So for '\n",
      "                                'example, at Verve, we made extensive use of '\n",
      "                                'creating different data warehouses. And each '\n",
      "                                'group that needed access to the data '\n",
      "                                'warehouse could be granted very granular '\n",
      "                                'access to only what they needed rather than '\n",
      "                                'the whole thing.',\n",
      "                                'And so they did a really good job with that '\n",
      "                                'part, right? And so a lot of other solutions '\n",
      "                                \"did not have the ability to do that. I don't \"\n",
      "                                'know of any NoSQL solutions that have the '\n",
      "                                'ability that Snowflake had. And then one '\n",
      "                                'other thing with Snowflake. That was very '\n",
      "                                'interesting that they chose to do is that '\n",
      "                                'their whole solution looks like a data '\n",
      "                                'warehouse. And what I mean by that is that '\n",
      "                                'data warehousing is at least 20, 30-year-old '\n",
      "                                'technical skill. So people with 20 years of '\n",
      "                                'data warehousing experience would go into '\n",
      "                                'Snowflake, and it would look familiar. It '\n",
      "                                \"looked like any other nuances because it's \"\n",
      "                                'not the same as to whatever they are using.',\n",
      "                                'But people coming from Oracle would recognize '\n",
      "                                'it as a data warehousing solution. It '\n",
      "                                \"wouldn't look unusual, right? So even though \"\n",
      "                                'under the covers, they worked in a unique '\n",
      "                                'way, they gave a flexible scalability, '\n",
      "                                'traditional data warehouses. Traditionally, a '\n",
      "                                'warehouse was not as scalable as Snowflake '\n",
      "                                'does. So being able to provide all the nice '\n",
      "                                'granular access, it looks like a data '\n",
      "                                'warehouse, super scalable, relatively '\n",
      "                                'affordable compared to other solutions. I '\n",
      "                                \"mean that's a pretty sweet spot for \"\n",
      "                                'Snowflake.'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Okay. Can you explain to me how pricing works '\n",
      "                                'for Snowflake?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': [\"I cannot. Loosely, it's based on the size of \"\n",
      "                                'your cluster, but unfortunately, I was doing '\n",
      "                                'technical analysis, and I need do price '\n",
      "                                'analysis. I do know that we spent significant '\n",
      "                                'money at Verve. It might have been other than '\n",
      "                                'Amazon. It was our largest vendor, right? So '\n",
      "                                \"depending on the size of the data that you're \"\n",
      "                                'storing and the size and the number of '\n",
      "                                'servers that you run is what you end up '\n",
      "                                'paying.'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': [\"Okay. And I guess, so when you're thinking \"\n",
      "                                'about Databricks, what valuating it for, I '\n",
      "                                'guess, like maybe what the use case was or '\n",
      "                                'what prompted you to do an evaluation in '\n",
      "                                '2016?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['Yes. So the reason why, and so I will tell '\n",
      "                                'you that I was a fan of Databricks. I wanted '\n",
      "                                'to move forward, and I was outvoted by the '\n",
      "                                'team. And we had like 7 people, 7 VP level '\n",
      "                                'decision-makers. And so I was in the '\n",
      "                                'minority. And I will tell you how I felt '\n",
      "                                \"personally about it, and I'll tell you what \"\n",
      "                                'the majority come. So what I liked about '\n",
      "                                'Databricks is that once you created the '\n",
      "                                'management UI that it offered would allow '\n",
      "                                'lesser engineers, right?',\n",
      "                                'So a lot of times with data pipeline systems, '\n",
      "                                'you need pretty sophisticated engineering '\n",
      "                                'talent to do this correctly and efficiently, '\n",
      "                                'right? Anyone with a keyboard, like there are '\n",
      "                                'so many libraries and so many convenient ways '\n",
      "                                'of putting these things together that lesser '\n",
      "                                'junior engineers, right, they can put it '\n",
      "                                'together. The problem is, is that junior '\n",
      "                                \"engineers don't necessarily understand all \"\n",
      "                                'the efficiency and cost factors involved in '\n",
      "                                \"what they're doing.\",\n",
      "                                \"And so what I felt like was so there's that \"\n",
      "                                \"aspect and then there's also just pure \"\n",
      "                                'resourcing. So any successful startup, at '\n",
      "                                \"least every successful start-up I've been a \"\n",
      "                                'part of is resource constrained. You always '\n",
      "                                'are trying to do more with less. You never '\n",
      "                                'have enough people, right? And in a scenario '\n",
      "                                'where you never have, and I would imagine '\n",
      "                                'this is true in a massive corporate '\n",
      "                                'environment as well.',\n",
      "                                \"Everyone's fighting for budget and resources \"\n",
      "                                \"and headcount. Everyone's being asked to do \"\n",
      "                                'more with less, right? So this is a common '\n",
      "                                'problem. And Databricks, what it does is it '\n",
      "                                'makes your engineers more efficient. They '\n",
      "                                \"don't have to write the same thing over and \"\n",
      "                                'over. Once you get it in size, then you can '\n",
      "                                'share it with someone else. And so other '\n",
      "                                'people could do it.',\n",
      "                                'So maybe you participate with maybe a senior '\n",
      "                                'engineer could overview a junior engineer '\n",
      "                                \"using this type of system. So you don't \"\n",
      "                                'require as much knowledge about the deep dark '\n",
      "                                'internals in order to be able to use '\n",
      "                                'something like Databricks. And even for '\n",
      "                                'senior engineers, once you have something '\n",
      "                                \"done inside of Databricks, it's convenient \"\n",
      "                                \"and it's there.\",\n",
      "                                'Setting up a system to run machine learning, '\n",
      "                                'like the worst-case scenario is that you have '\n",
      "                                'to set everything up every time you do it. '\n",
      "                                \"And inevitably, you don't want to do that. So \"\n",
      "                                'either you buy a system like Databricks that '\n",
      "                                'makes the setup really easy and point and '\n",
      "                                'click in a UI, or you end up building your '\n",
      "                                'own home brewed technology, right? What I saw '\n",
      "                                'happening at Verve, we were building our home '\n",
      "                                'brewed technology, and I saw a value in '\n",
      "                                'Databricks but not home brewing. We were '\n",
      "                                'resource constrained.',\n",
      "                                'And I wanted to be able to go faster. I '\n",
      "                                'wanted non data scientists to be able to go '\n",
      "                                'into the data set and attempt to do things. '\n",
      "                                'So for example, I was managing ad tech team, '\n",
      "                                'one of my teams would, every once in a while, '\n",
      "                                \"they've had some pre cycles or they were \"\n",
      "                                'building technology around the machine '\n",
      "                                'learning.',\n",
      "                                'It would have been convent for them to be '\n",
      "                                'able to go in and run an experiment using '\n",
      "                                'something like Databricks without having to '\n",
      "                                'know all the deep dark internals of how the '\n",
      "                                'pipeline works, going into Databricks and '\n",
      "                                'being able to put a few things in there to '\n",
      "                                'run a job, to get an experimental data set in '\n",
      "                                'order to test their system, that would have '\n",
      "                                'been a very convenient thing.',\n",
      "                                'So from my perspective, I was like, '\n",
      "                                'Databricks seems like a great thing for '\n",
      "                                'everyone, win, win, win. The only downside '\n",
      "                                'was what the majority felt is that it was '\n",
      "                                \"just a UI, and we've got more technology. And \"\n",
      "                                'the majority also felt that for what we would '\n",
      "                                'get there was a switching cost and then the '\n",
      "                                \"actual maintenance cost that they didn't feel \"\n",
      "                                'was valuable. I disagreed. I think they were '\n",
      "                                'wrong in all accounts.',\n",
      "                                'Eventually, I mean, there was things that we '\n",
      "                                'were going to do with the inebriated that '\n",
      "                                'year but ended up getting done 2, 3 years '\n",
      "                                \"later. I can't say for sure that Databricks \"\n",
      "                                'would have accelerated that, but it would '\n",
      "                                'have opened up other resources to help with '\n",
      "                                'those efforts, right?',\n",
      "                                'So that was kind of the decision-making '\n",
      "                                'process that we went through with Databricks. '\n",
      "                                'A decision-making process would happen today '\n",
      "                                'even with Databricks new and expanded '\n",
      "                                \"capabilities, except that they'd probably be \"\n",
      "                                'able to win some hearts over with some of '\n",
      "                                \"their more advanced capabilities they've \"\n",
      "                                'built recently.'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Okay. So you said that your team felt that '\n",
      "                                \"there'd be a switching cost. I wondered if \"\n",
      "                                'you could talk a little bit more about what '\n",
      "                                'the switching cost is?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['So whenever you adopt a new technology, there '\n",
      "                                'is a cost of moving the existing technologies '\n",
      "                                \"over into the new one. There's also, if you \"\n",
      "                                'think about it, either you have to pay the '\n",
      "                                'price of switching over completely or you '\n",
      "                                'have to split the brains of people that feed '\n",
      "                                'the boots on the ground, you have to split '\n",
      "                                'their brains to work on 2 different systems, '\n",
      "                                \"right? So those phenomena are what's referred \"\n",
      "                                'to as switching cost.',\n",
      "                                \"So when the majority was saying, hey, we'd \"\n",
      "                                \"have to switch. We'd already had a way of \"\n",
      "                                'doing things, and we had partially built a '\n",
      "                                'system that could do what Databricks did, '\n",
      "                                'right? And just throwing away something '\n",
      "                                \"that's partially built. I personally am not. \"\n",
      "                                \"I think that it's a sign of technical palace \"\n",
      "                                'in order to be able to throw away partial '\n",
      "                                \"effort from scratch. To me, that's okay.\",\n",
      "                                \"A lot of engineers don't feel that way. But \"\n",
      "                                'with regards to switching costs, the '\n",
      "                                'switching cost will seem more painful. On top '\n",
      "                                \"of the switch, you're throwing away work that \"\n",
      "                                \"you've already done. So a lot of times that \"\n",
      "                                'factors into the decision-making process. The '\n",
      "                                'amount of time that we take to switch '\n",
      "                                'Databricks versus the amount of time we think '\n",
      "                                \"it will take to finish what we're already \"\n",
      "                                'doing is part of the decision-making '\n",
      "                                'process.'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Yes. And I guess going back to Snowflake, so '\n",
      "                                'how hard would it be to switch from Snowflake '\n",
      "                                'to a competing solution? Yes. How difficult '\n",
      "                                'and how long would it be to switch?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': [\"Yes. So I mean, a lot of times, it's going to \"\n",
      "                                'depend on the technology. Unfortunately, I '\n",
      "                                'cannot give a general answer just because '\n",
      "                                'there is no general answer. I will tell you '\n",
      "                                \"that I'm a member of the LA CTO form. And \"\n",
      "                                'like, literally, there was a chat the other '\n",
      "                                'day about someone who had switched off of '\n",
      "                                'Snowflake. And he said in his organization, '\n",
      "                                'it was no problem.',\n",
      "                                'I will tell you that for Verve, it took over '\n",
      "                                'a year, 1.5 years total to completely migrate '\n",
      "                                'from the things that we had been doing for 5 '\n",
      "                                'to 8 years, right? So depending on the age of '\n",
      "                                \"the technology for 5 to 8 years we've doing \"\n",
      "                                'it one way, and it took about a year to '\n",
      "                                'migrate all of those different use cases over '\n",
      "                                \"in totality, right? Now that's dozens of \"\n",
      "                                'different use cases. So generally, you might '\n",
      "                                'move one use case,  another use case.',\n",
      "                                'Oh, these 3 are all linked together, move '\n",
      "                                \"those 3 now. And so when you're migrating \"\n",
      "                                \"over, you're dealing with 2 systems. And so \"\n",
      "                                'that was the approach that we took at Verve. '\n",
      "                                'It made sense for us at the time because the '\n",
      "                                'risk of losing these valuable data sets or '\n",
      "                                'not even losing it, but just the risk of any '\n",
      "                                'kind of corruption in the new data set '\n",
      "                                'required that we kept the old data set '\n",
      "                                'running at the same time.',\n",
      "                                \"So Verve's technique for migrating would be, \"\n",
      "                                \"oh, look, there's a new, we're running a \"\n",
      "                                'pipeline one way. And so for example, if we '\n",
      "                                'were running stuff, pulling it out of S3, '\n",
      "                                'running at EMR and then dropping it off in a '\n",
      "                                \"data warehouse solution. So now we're talking \"\n",
      "                                \"about, well, we're going to write a job in \"\n",
      "                                \"Databricks that's going to pull it out of \"\n",
      "                                'Snowflake and run it on Spark, right?',\n",
      "                                \"Those are 2 different, well so I'm going to \"\n",
      "                                'call those pipelines for this conversation. '\n",
      "                                'Those 2 different pipelines are running at '\n",
      "                                'Verve, we would run them simultaneously for '\n",
      "                                'up to 3 months to ensure that no financial '\n",
      "                                \"information was being lost. And then we'd \"\n",
      "                                'call it done, then we could shut off the old '\n",
      "                                '1 and do the new one.',\n",
      "                                'So in some companies, that is going to be '\n",
      "                                'mandatory. In other companies, the faster '\n",
      "                                'switches are going to be when you have a data '\n",
      "                                'set and you can validate that the new data '\n",
      "                                'set is equivalent to the old data set, then '\n",
      "                                'it would be a fast switch, right? Verve did '\n",
      "                                'not have that capability.'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': [\"Okay. That's helpful. And then, I guess, how \"\n",
      "                                'big was Verve in terms of number of '\n",
      "                                'employees?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['At the end, it was 100. When I joined, it was '\n",
      "                                'about 100. So 2014 has about 100, it grew up '\n",
      "                                'to 250, 260 million in 2018. And then the '\n",
      "                                'business started struggling in 2018 and ended '\n",
      "                                'up at about 100 at the exit.'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['And so how many people were using Snowflake '\n",
      "                                'and what the teams were they on?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['Well, do you mean direct users? Or do you '\n",
      "                                'mean like end users that would see the output '\n",
      "                                'that came out of Snowflake?'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Direct users.'], 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['So direct users was probably, let me seen '\n",
      "                                \"there's 6 or 6. So the data team itself had 4 \"\n",
      "                                'people, the data warehouse team had 2 onshore '\n",
      "                                'and fluctuated 4 to 10 offshore resources, '\n",
      "                                'the data science team had no less than 4 '\n",
      "                                'people, but as many as 8 using Snowflake and '\n",
      "                                'then the ad tech team had between 3 and 7. So '\n",
      "                                'probably on the low end would be 15 engineers '\n",
      "                                'and on the high end, it was 30, 40.'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Okay. And then how do you think about '\n",
      "                                'measuring your return on investment in '\n",
      "                                'Snowflake?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['Yes. So yes. Let me think about this. So, '\n",
      "                                'again, when the finances and Snowflake at '\n",
      "                                'Verve, I did not participate in those '\n",
      "                                'conversations. And so I can tell you that for '\n",
      "                                'me, personally, the way that I value '\n",
      "                                'Snowflake is I understand how many engineers '\n",
      "                                'it would take to not use Snowflake. So if I '\n",
      "                                'was going to do an evaluation, I would say, '\n",
      "                                'how many engineers do I need to hire '\n",
      "                                'full-time in order to replace this '\n",
      "                                'technology.',\n",
      "                                'And so if I was spending $100,000 a year on '\n",
      "                                \"Snowflake, I can't even hire an engineer that \"\n",
      "                                'could do the same thing at Snowflake for '\n",
      "                                '$100,000 a year. As a matter of fact, I might '\n",
      "                                'need 2 or 3 or 4, right, just to manage the '\n",
      "                                'infrastructure and the things that Snowflake '\n",
      "                                'does and it may or not even be as reliable. '\n",
      "                                'So if I can pay for Snowflake for less than 4 '\n",
      "                                \"engineers a year, and that's just straight \"\n",
      "                                'dollar math, right?',\n",
      "                                'It has nothing to do with like switching '\n",
      "                                'costs and all the other -- not switching '\n",
      "                                'costs. What I mean is maintenance costs, '\n",
      "                                'right? So all the maintenance costs of doing '\n",
      "                                'all the things that are not Snowflake, the '\n",
      "                                'lack of support and doing it -- rolling it '\n",
      "                                \"yourself, there's -- intact, a lot of junior \"\n",
      "                                'engineers make the mistake of thinking they '\n",
      "                                'can build it themselves, right?',\n",
      "                                \"And after you've seen enough home built \"\n",
      "                                'Fiascos, you start to understand the value of '\n",
      "                                'buying a solution like Snowflake. I will tell '\n",
      "                                'you, you should know that everything that '\n",
      "                                \"I've said about Snowflake, so with \"\n",
      "                                'Databricks, I was on the losing side. Same '\n",
      "                                'thing with Snowflake. I was against Snowflake '\n",
      "                                'at first.',\n",
      "                                'I felt like we did not need Snowflake that '\n",
      "                                'there was NoSQL solutions that would meet our '\n",
      "                                'needs. And then I was in the minority on that '\n",
      "                                'decision, and it turns out that I was wrong. '\n",
      "                                'And I got to see the benefit of Snowflake, '\n",
      "                                'and I became a pretty big snowflake fan.'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['So I guess do you think the differences '\n",
      "                                'between Snowflake and its competitors have '\n",
      "                                'narrowed or widened over time?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['So I would say, recently up until their IPO, '\n",
      "                                \"it's been widening, but the fact that they've \"\n",
      "                                'gone IPO is certainly going to bring heat. I '\n",
      "                                \"mentioned this before, I didn't think \"\n",
      "                                'Snowflake stood a chance against these '\n",
      "                                'cloud-managed solutions that Google and '\n",
      "                                'Amazon offer. And those solutions still are '\n",
      "                                \"there, they're still robust.\",\n",
      "                                'One of the advantages with Snowflake that '\n",
      "                                \"those guys don't have is you could probably \"\n",
      "                                'migrate from Google to Amazon pretty easily. '\n",
      "                                'However long it took to move the data? I '\n",
      "                                'mean, you can be up and running in a '\n",
      "                                'different cloud, being able to switch clouds, '\n",
      "                                'gives you a lot of leverage when negotiating '\n",
      "                                'with those cloud providers. I would say, I '\n",
      "                                \"guess, it's a long-winded way of me saying \"\n",
      "                                \"that, I don't know.\",\n",
      "                                'I can see an argument being made both ways. '\n",
      "                                \"Again, I'm not, like I know Snowflake, I know \"\n",
      "                                \"like Dynamo and Amazon's offering, I know \"\n",
      "                                \"Google's offerings. I don't know of any other \"\n",
      "                                'tech, like closely compare all the other '\n",
      "                                'database technologies that I know compared to '\n",
      "                                'Snowflake are all NoSQL solutions. So in that '\n",
      "                                'context, Snowflake is pretty unique. So in my '\n",
      "                                'perspective, given the knowledge that only I '\n",
      "                                \"have, it seems like it's expanding.\"],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['And so I guess, what is the advantage of '\n",
      "                                'being a sequel database specifically?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': [\"So it's a little bit technical, but a SQL \"\n",
      "                                'database is another phrase of people use as '\n",
      "                                \"relational database, that's a technical a \"\n",
      "                                'term. And in a relational database, you '\n",
      "                                'maintain relationships. So the classic case '\n",
      "                                'is like if you have an account, like a bank '\n",
      "                                \"account, being able to say that I've got \"\n",
      "                                \"users, and I've got balances in 2 different \"\n",
      "                                'databases.',\n",
      "                                'I can say, like if I have deposits and '\n",
      "                                'withdrawals in one table and users at '\n",
      "                                \"another, I'm able to store the relationship \"\n",
      "                                'between every data entry between 2 different '\n",
      "                                'tables, right? Think of it, do you use Excel '\n",
      "                                'at all in your work?'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Yes.'], 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['Yes. So imagine having an Excel spreadsheet '\n",
      "                                'being able to link cells between the tables, '\n",
      "                                \"Excel maintains that relationship. So that's \"\n",
      "                                \"kind of what I'm talking about?\"],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Yes.'], 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['Yes. So those relationships are maintained by '\n",
      "                                'Excel, a relational database works the same '\n",
      "                                'way. NoSQL databases -- maintaining those '\n",
      "                                'relationships can be computationally '\n",
      "                                'expensive. And so NoSQL databases started '\n",
      "                                'getting popularity, 2005 to 2015, they gained '\n",
      "                                'a lot of popularity because they could store '\n",
      "                                'bigger data and access it faster because they '\n",
      "                                \"didn't maintain those relationships. In some \"\n",
      "                                \"use cases, that's okay.\",\n",
      "                                'In other use cases, it would be terrible. For '\n",
      "                                'a banking app it would be terrible, for a '\n",
      "                                'social sharing site that if you lost '\n",
      "                                \"someone's photo, not a big deal, right? But \"\n",
      "                                'depending on the use case, you might not need '\n",
      "                                'those relationships. And what people found is '\n",
      "                                'that they would be using these NoSQL '\n",
      "                                \"databases. And then all of sudden, they'd be \"\n",
      "                                'like, oh, wait, I do need that data '\n",
      "                                'integrity. I do need those relationships '\n",
      "                                'maintained.',\n",
      "                                'This NoSQL solution makes it very hard, but '\n",
      "                                \"Dang it's gast, and Dang, I have a lot of \"\n",
      "                                'data, right? So when Snowflake came around, '\n",
      "                                'Snowflake like, well, you could have it all, '\n",
      "                                \"and they've won a lot of people over, myself \"\n",
      "                                'included.'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Okay. So last question. On a scale of 0 to '\n",
      "                                '10, how likely are you to recommend Snowflake '\n",
      "                                'to a colleague or a peer? And then what are '\n",
      "                                'your top 3 reasons for your score?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['Yes. So unfortunately, every decision in '\n",
      "                                'computing is the answer is literally, it '\n",
      "                                \"depends, right? And so there's always some \"\n",
      "                                'context necessary. If someone had a '\n",
      "                                'relational data problem that they needed to '\n",
      "                                'scale up and down, and the switching costs '\n",
      "                                \"weren't terrible. It would be a 10, right? \"\n",
      "                                'And then depending on the particulars of '\n",
      "                                'their situation, I might drop that a little '\n",
      "                                'bit.',\n",
      "                                'If switching costs were painful, I might drop '\n",
      "                                \"it down to an 8. If they didn't need \"\n",
      "                                \"relational data, I wouldn't recommend \"\n",
      "                                'Snowflake. Snowflake solves a pretty well '\n",
      "                                'understood class of problems, which is data '\n",
      "                                'warehousing. So if you have a data '\n",
      "                                \"warehousing problem, it's at 9.5 o Snowflake. \"\n",
      "                                'And the only hesitation around 0.5 would be '\n",
      "                                'if cost was something that your data is small '\n",
      "                                \"and your costs where -- you're hypersensitive \"\n",
      "                                'to the cost that maybe you do roll it your '\n",
      "                                'own for a little while?'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['And then one question. What is that Snowflake '\n",
      "                                'due to either additions that you had wished '\n",
      "                                'for or improvements they could think.'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': [\"I can't think of any for the use cases that I \"\n",
      "                                'was meaning Snowflake for, it did at all, '\n",
      "                                'right? And it did more than what I needed, '\n",
      "                                \"right? So it's a very robust technology. I \"\n",
      "                                'mean, like, the only thing I can think of is '\n",
      "                                'that, I mean, as a supernerd engineer, I wish '\n",
      "                                'I could use my own editor to edit, but so '\n",
      "                                \"it's really esoteric.\"],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Yes. And what about their customer service? '\n",
      "                                'Did you have any experience with them?'],\n",
      "                 'speaker': 'Tegus Client'},\n",
      "                {'paragraphs': ['I did not, well, not me personally, but the '\n",
      "                                'team I managed, they talk to them, all of the '\n",
      "                                'days and they were on this one with them all '\n",
      "                                'the time. So when we were migrating to '\n",
      "                                'Google, they gave us rate, but they helped us '\n",
      "                                'migrate to Google. Verve was one of the first '\n",
      "                                'Google Cloud, say, customers. So we kind of '\n",
      "                                'had early access. So I did not hear any '\n",
      "                                'complaints, right? And so I worked with that '\n",
      "                                'team. A couple of the people that were part '\n",
      "                                'of the migration, reported to me. I did a '\n",
      "                                'direct experience but nobody complained. We '\n",
      "                                'got what we needed.'],\n",
      "                 'speaker': 'Former VP Technology at Verve'},\n",
      "                {'paragraphs': ['Awesome. Okay. Cool. Well, thank you so much. '\n",
      "                                'We made it to the end of the questions and I '\n",
      "                                'appreciate that your thorough explanations '\n",
      "                                'for me and bearing with my lack of technical '\n",
      "                                'knowledge, but I definitely learned a lot. '\n",
      "                                \"I'm super positive. Thanks again, and have a \"\n",
      "                                'great rest today.'],\n",
      "                 'speaker': 'Tegus Client'}]}\n"
     ]
    }
   ],
   "source": [
    "# Read JSON file\n",
    "with open('../data/ml_exercise_conversation_cleaned.json', 'r') as json_file:\n",
    "    interview = json.load(json_file)\n",
    "\n",
    "# Pretty print the JSON data\n",
    "pprint(interview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Named Entity Recognition\n",
    "\n",
    "Pull out named entities from the interview using a pretrained NER model from Hugging Face. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"max\")  # Word entity will be the token with the maximum score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 61/61 [00:31<00:00,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MapReduce', 'Dynamo', 'MongoDB', 'LA CTO', 'Snowflakes', 'Redshift', 'Azure', 'Google', 'Google Cloud', 'Oracle', 'Amazon', 'Excel', 'Snowflake', 'UI', 'EMR', 'Rubicon', 'Apache', 'Verve', 'Cassandra', 'Elastic', 'Couchbase', 'Gartner', 'Databricks'}\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "entities = set()\n",
    "\n",
    "for thought in tqdm(interview['utterances']):\n",
    "    _thought = thought['paragraphs']\n",
    "    for paragraph in _thought:\n",
    "        ner_results = nlp(paragraph)\n",
    "        orgs = [org['word'] for org in ner_results if org['entity_group']=='ORG' and org['score'] > 0.75]\n",
    "        entities.update(orgs)\n",
    "\n",
    "print(entities)\n",
    "print(len(entities))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Competitor Classification \n",
    "\n",
    "Now that we have our list of products and companies, we want to classify whether they are competitors to the target company (Snowflake).\n",
    "\n",
    "Since we only have one example, I will rely on pretrained models. There is a max token length for the model, so I will batch the interview and iteratively pass through the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model pretrained on MNLI (Multi-Genre Natural Language Inference)\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "model = BartForSequenceClassification.from_pretrained('facebook/bart-large-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_competitor(batched_lists, possible_competitor, target_org):\n",
    "    \"\"\"\n",
    "    Classify a possible competitor company or producat as being a competitor to Snowflake based on the\n",
    "    interview context using a pretrained Sequence classification model.\n",
    "    \"\"\"\n",
    "    competitor_probability = []\n",
    "    for idx, batch in enumerate(batched_lists):   \n",
    "        # pose sequence as a NLI premise\n",
    "        premise = \" \".join(batched_lists[idx])\n",
    "\n",
    "        hypothesis = f'{possible_competitor} and {target_org} are competitors.'\n",
    "\n",
    "        # run through model pre-trained on MNLI to get premise and hypothesis embeddings\n",
    "        input_ids = tokenizer.encode(premise, hypothesis, return_tensors='pt', max_length=1024, truncation=True)\n",
    "        logits = model(input_ids)[0]  # logits - activations from final layer of the model\n",
    "\n",
    "        # we throw away \"neutral\" (dim 1) and take the probability of \"entailment\" (2) as the probability\n",
    "        # of the label being true\n",
    "        entail_contradiction_logits = logits[:,[0,2]]\n",
    "        probs = entail_contradiction_logits.softmax(dim=1) # convert logits to a probability using sigmoid across output classes\n",
    "        true_prob = probs[:,1].item() * 100\n",
    "        competitor_probability.append(true_prob)\n",
    "\n",
    "    return max(competitor_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try using paragraphs that contain Snowflake to try to tease out the entity's relationship to Snowflake\n",
    "context = [thought['paragraphs'] for thought in interview['utterances']]\n",
    "\n",
    "sf_context = []\n",
    "for chunk in context:\n",
    "    concat_chunk = \" \".join([paragraph for paragraph in chunk])\n",
    "    if \"Snowflake\" in concat_chunk:\n",
    "        sf_context.append(concat_chunk)\n",
    "len(sf_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the text into batches to avoid max token length issues\n",
    "batch_size = 4\n",
    "batched_lists = [sf_context[i:i + batch_size] for i in range(0, len(sf_context), batch_size)]\n",
    "len(batched_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022\n",
      "1022\n",
      "1022\n",
      "1022\n",
      "1022\n",
      "1022\n",
      "162\n"
     ]
    }
   ],
   "source": [
    "# researched another batching method that is better\n",
    "tokens = tokenizer.encode_plus(\" \".join(sf_context), add_special_tokens=False, return_tensors='pt')\n",
    "input_id_chunks = tokens['input_ids'][0].split(1022)  # 1022 due to CLS and PAD special tokens we want to add later\n",
    "mask_chunks = tokens['attention_mask'][0].split(1022)\n",
    "\n",
    "for tensor in input_id_chunks:\n",
    "    print(len(tensor))\n",
    "\n",
    "# then stack and run through the model to generate probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out Snowflake from the entity list\n",
    "filtered_entities = {item for item in entities if not item.startswith(\"Snowflake\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 1/21 [01:39<33:19, 99.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MapReduce: 83.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 2/21 [03:10<29:48, 94.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamo: 97.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 3/21 [04:32<26:38, 88.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MongoDB: 80.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 4/21 [06:05<25:39, 90.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LA CTO: 88.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 5/21 [07:37<24:18, 91.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redshift: 84.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 6/21 [09:03<22:18, 89.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure: 83.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 7/21 [10:30<20:38, 88.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google: 98.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 8/21 [11:56<19:00, 87.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Cloud: 99.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 9/21 [13:23<17:31, 87.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle: 72.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 10/21 [15:00<16:34, 90.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon: 97.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 11/21 [16:32<15:09, 90.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel: 89.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 12/21 [17:57<13:22, 89.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UI: 87.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 13/21 [19:24<11:46, 88.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMR: 92.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 14/21 [20:51<10:15, 87.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rubicon: 85.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 15/21 [22:19<08:48, 88.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache: 83.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 16/21 [23:45<07:17, 87.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verve: 91.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 17/21 [25:16<05:53, 88.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cassandra: 95.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 18/21 [26:51<04:31, 90.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic: 83.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 19/21 [28:18<02:58, 89.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couchbase: 91.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 20/21 [29:50<01:30, 90.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gartner: 87.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [31:20<00:00, 89.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Databricks: 94.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for org in tqdm(filtered_entities):\n",
    "    competitor_probability = classify_competitor(batched_lists=batched_lists,\n",
    "                                                 possible_competitor=org,\n",
    "                                                 target_org='Snowflake')\n",
    "    print(f\"{org}: {competitor_probability:0.2f}%\")\n",
    "    results[org] = competitor_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>competitor_probability</th>\n",
       "      <th>competitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Google Cloud</td>\n",
       "      <td>99.035293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Google</td>\n",
       "      <td>98.396146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dynamo</td>\n",
       "      <td>97.901756</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>97.704494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cassandra</td>\n",
       "      <td>95.284843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Databricks</td>\n",
       "      <td>94.639993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EMR</td>\n",
       "      <td>92.721331</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Couchbase</td>\n",
       "      <td>91.748416</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Verve</td>\n",
       "      <td>91.669631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Excel</td>\n",
       "      <td>89.589107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LA CTO</td>\n",
       "      <td>88.323200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UI</td>\n",
       "      <td>87.710512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gartner</td>\n",
       "      <td>87.029588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rubicon</td>\n",
       "      <td>85.822308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Redshift</td>\n",
       "      <td>84.502423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MapReduce</td>\n",
       "      <td>83.623219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Azure</td>\n",
       "      <td>83.563632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Elastic</td>\n",
       "      <td>83.261633</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Apache</td>\n",
       "      <td>83.103925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MongoDB</td>\n",
       "      <td>80.834585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Oracle</td>\n",
       "      <td>72.041655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          entity  competitor_probability  competitor\n",
       "7   Google Cloud               99.035293           1\n",
       "6         Google               98.396146           1\n",
       "1         Dynamo               97.901756           1\n",
       "9         Amazon               97.704494           1\n",
       "16     Cassandra               95.284843           1\n",
       "20    Databricks               94.639993           1\n",
       "12           EMR               92.721331           0\n",
       "18     Couchbase               91.748416           0\n",
       "15         Verve               91.669631           0\n",
       "10         Excel               89.589107           0\n",
       "3         LA CTO               88.323200           0\n",
       "11            UI               87.710512           0\n",
       "19       Gartner               87.029588           0\n",
       "13       Rubicon               85.822308           0\n",
       "4       Redshift               84.502423           0\n",
       "0      MapReduce               83.623219           0\n",
       "5          Azure               83.563632           0\n",
       "17       Elastic               83.261633           0\n",
       "14        Apache               83.103925           0\n",
       "2        MongoDB               80.834585           0\n",
       "8         Oracle               72.041655           0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort results in order of probability\n",
    "results_df = pd.DataFrame(results.items(), columns=['entity', 'competitor_probability'])\n",
    "\n",
    "# create binary classification based on minimum probability threshold\n",
    "results_df['competitor'] = np.where(round(results_df['competitor_probability']) >= 95, 1, 0)\n",
    "results_df.sort_values('competitor_probability', ascending=False, inplace=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "results_df.to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tegus-aQ_93WNH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
